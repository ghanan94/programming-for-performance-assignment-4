\documentclass[12pt]{article}

\usepackage[letterpaper, hmargin=0.75in, vmargin=0.75in]{geometry}
\usepackage{float}
\usepackage{url}


\pagestyle{empty}

\title{ECE 459: Programming for Performance\\Assignment 4}
\author{Ghanan Gowripalan}
\date{\today}

\begin{document}

\maketitle

\newpage
\section*{Part 1: Performance}

\paragraph{Parameters.} Using the default parameters resulted in the 'spedup' implementation actually performing worse than the original because there was not enough work in the queues to be completed. To show any benefits to the changes made to the program to improve performance, the queue should almost never be empty. To achieve this, the arrival rate was kept as high as possible so. As most of the changes did not affect how servicing of jobs was done, the service time was unchanged. To make sure that assignment of jobs did not affect results, the default (round-robin) assignment was used. This is to make sure each queue gets assigned approximately an equal amount of work; random assignment could put more jobs to certain queues than others, which would make it seem like there was something negatively impacting performance. Lastly, to try and reduce the impact of thread scheduling, the amount of queues was kept low - each queue is assigned at least one thread. Speed up was obtained when executed with the following parameters:

\begin{table}[H]
  \centering
  \begin{tabular}{lr}
    {\bf Parameter} & {\bf Value} \\
    \hline
    Jobs & 100000 (default) \\
    Policy & 2 (default) \\
    Lamda & 1 \\
    Max Rounds & 2000 (default) \\
    Load Balaning & 0 (default) \\
    Number of Queues & 2 \\
  \end{tabular}
  \caption{Execution parameters for part 1}
  \label{tbl-part1-params}
\end{table}

\begin{table}[H]
  \centering
  \begin{tabular}{lrr}
    & {\bf No speedup} & {\bf Speedup} \\
    \hline
    Run 1 & 2.756354 & 0.639008 \\
    Run 2 & 2.724420 & 0.675093 \\
    Run 3 & 2.721033 & 0.736818 \\
    \hline
    Average & 2.733902 & 0.683639 \\
  \end{tabular}
  \caption{90th percentile for execution}
  \label{tbl-part1-90th-percentile}
\end{table}

\paragraph{Results.} Without speedup, an average 90th percentile value of 2.734 was obtained. With the speedup, a 90th percentile of 0.684 was obtained. This resulted in a total speed up of approximately 4.0x. The program was executed on my own computer (not the {\tt ece459-1} server).

\paragraph{Changes.} The speedup was obtained by using mutliple threads for each queue. Creating extra threads adds overhead so the gains must outweigh the losses in performance.

\paragraph{Possible Changes.} Another change that can be done to improve performance of the program is to use a {\tt tail} pointer to the linked list ({\tt queue\_t}). If a {\tt tail} pointer was added to the {\tt queue\_t} data structure, adding jobs to the queue can occur in \( O(1) \) runtime instead of \( O(n) \) where \( n \) is the number of jobs in the queue currently). However, tests showed that this actually negatively impacted the 90th percentile results. This is because jobs would be added to the queue must faster compared to the original implementation, meaning that more jobs would be sitting in the queue throughout the execution of the program. Since the objective of this report is to obtain the best speedup and not to make the program as efficient as possible, this change was not implemented. However, the code that could be used to make this change is in the {\tt add\_to\_queue} function, but commented out (line {\tt 76} to replace lines {\tt 70 - 74}).

\pagebreak
\section*{Part 2: Load Balancing}

\paragraph{Parameters.} To really show the benefits of load balancing, service time should be relativly high. This is so that the overhead of load balancing is minimal compared to the actual work that need to be done for each queue; if the service time was too low, the load balancing overhead would negatively impact performance. However, with increased, service times, the number of idle jobs in the queue increases significantly. Idle jobs in any queue should be kept relatively low (5 - 20) to show the benefits of load balancing. If there were too many jobs in any queue, queues will get 'out-of-balanced' before they start executing jobs that were moved around by the load balancer. To accomodate this, the arrival rate had to be reduced. Now that arrival rates are low and service times are high, the time to execute the program increased significantly. To reduce program execution time, the number of jobs was reduced so that testing and development can be done quicker, while still showing an accurate representation of the benefits (or drawbacks). Speed up was obtained when executed with the following parameters:
\begin{table}[H]
  \centering
  \begin{tabular}{lr}
    {\bf Parameter} & {\bf Value} \\
    \hline
    Jobs & 10000 \\
    Policy & (Depends on test) \\
    Lamda & 250 \\
    Max Rounds & 10000 \\
    Load Balaning & (Depends on test) \\
    Number of Queues & 8 \\
  \end{tabular}
  \caption{Execution parameters for part 2}
  \label{tbl-part2-params}
\end{table}

\begin{table}[H]
  \centering
  \begin{tabular}{lrrrr}
    & {\bf RA - NLB} & {\bf RA - LB} & {\bf RR - NLB} & {\bf RR - LB} \\
    \hline
    Run 1 & 0.194987 & 0.082441 & 0.031668 & 0.023877 \\
    Run 2 & 0.106769 & 0.038258 & 0.106431 & 0.085127 \\
    Run 3 & 0.121297 & 0.038827 & 0.065667 & 0.029686 \\
    \hline
    Average & 0.141018 & 0.053265 & 0.067922 & 0.046230 \\
  \end{tabular}
  \caption{90th percentile for execution (RA = random assignment policy; RR = round robin assignment policy; NLB = no load balancing; LB = load balancing)}
  \label{tbl-part2-90th-percentile}
\end{table}

\paragraph{Random Assignment Poicy Results.} Without loadbalancing, an average 90th percentile value of 0.141 was obtained. With the load balancing, a 90th percentile of 0.053 was obtained. This resulted in a total speed up of approximately 2.7x. The program was executed on my own computer (not the {\tt ece459-1} server).

\paragraph{Round Robin Policy Results.} Without loadbalancing, an average 90th percentile value of 0.068 was obtained. With the load balancing, a 90th percentile of 0.046 was obtained. This resulted in a total speed up of approximately 1.5x. The program was executed on my own computer (not the {\tt ece459-1} server).

\paragraph{Results' Conclusion.} Load balancing seems to be more effective when the assignment policy is random vs round-robin. This would make sense as with random assignment, not all queues may get an even ammount of work (the expected ammount of distributed work over an infinite amount of jobs is even but we are using finite amounts of work). With round-robin, all queues will initially get an even amount of jobs.

\paragraph{Data Structure Modifications.} The load balancing was implemented by first modifying the {\tt queue\_t} and {\tt job\_t} data structures.
\begin{description}
  \item [Tail pointer] Originally, the {\tt queue\_t} data structure was a linked list (of {\tt job\_t} nodes) with a pointer to the head of the linked list only. This was the first thing that was modified: a pointer to the tail of the linked list was added to make additions to the linked list faster. With this modification, the runtime to add a new job to the queue was reduced from \( O(n) \) to \( O(1) \) (where \( n \) was the number of jobs currently in the queue).

  \item [Doubly linked list] Originally, the {\tt queue\_t} data structure was a singly linked list (of {\tt job\_t} nodes). This was the next thing to be modified to allow for easy access to nodes that may be closer to the tail than the head of the linked list. To accomdate this, the singly linked list was modified to a doubly linked list. The modifications were done to the {\tt job\_t} data structur. A {\tt prev} pointer was added so that traversing the linked list in reverse order can be done more efficiently.
\end{description}

\paragraph{Load Balancing Algorithm.} The load balancing was implemented using a dedicated load balancing thread that will loop forever doing the following tasks until all jobs are completed:
\begin{enumerate}
  \item Sleep for 0.2 seconds.
  \item Obtain the locks for each of the queues.
  \item Calcualte average number of rounds of work to be done for all queues.
  \item If average number of rounds of work to be done is greater than maxium allowed rounds per job, then do the load balancing.
  \item Release the locks for each of the queues.
\end{enumerate}

\paragraph{} The load balancing algorithm load balances based on the number of rounds of work that needs to be completed. This is a more accurate representation of how much work each queue has to do compared with just looking at the number of jobs in a queue because different jobs will have varying amounts of work to do (different service times). The goal is to make each queue have similar (if not identical) amounts of work to do. To load balanace:
\begin{description}
  \item [Remove 'excess' jobs] First 'excess' jobs (jobs that make queues unbalanced relative to the expected average amount of work to do because they make the queue do too much work), are removed form the queue and added to a seperate list of all 'excess' jobs. After this step,
  \item [Add to 'light' queues] Next, queues that are 'light' (queues where their total amount of work to do is less than the expected average average amount of work to do), will have jobs added to them to give them more work to do and balance out the work. The jobs given to these queues are taken from the jobs that were removed form the previous step and added to a list of 'excess' jobs.
\end{description}
\paragraph{} After load balancing, the queues will have relateively equal amounts of work with some variance, but the variance after load balancing is a lot less than what it was before load balancing.

\end{document}
